# ðŸ“˜ Guida Esplicativa al Progetto - F1 Overtake Prediction

> **Nota**: Questo file non viene committato. Serve come guida per capire e spiegare il progetto durante la presentazione.

---

## ðŸŽ¯ Obiettivo del Progetto

Creare un sistema di **Machine Learning** che predice la probabilitÃ  di sorpasso in Formula 1, simulando un muretto box durante una gara.

**PerchÃ© questo progetto?**
- I sorpassi in F1 sono eventi **rari ma cruciali** per le strategie di gara
- I team usano dati telemetrici per prendere decisioni in tempo reale
- Ãˆ un problema di **classificazione binaria sbilanciata** (pochi sorpassi vs tanti non-sorpassi)

---

## ðŸ“ Struttura e File

### `pipeline/data_loader.py`
**Cosa fa:** Scarica i dati telemetrici ufficiali F1 dal GP di Monza (2022-2024).

**PerchÃ© FastF1?**
- Ãˆ l'unica libreria Python che accede ai dati ufficiali F1
- Fornisce dati giro per giro: tempo, posizione, gomme
- Dati reali = risultati piÃ¹ significativi rispetto a dati sintetici

**PerchÃ© solo Monza?**
- Circuito con molte opportunitÃ  di sorpasso (rettilineo principale, Curva Grande)
- OmogeneitÃ  dei dati (stesso circuito, condizioni simili)
- 3 anni = ~1500 giri utili per il training

---

### `pipeline/relative_feature_builder.py`
**Cosa fa:** Trasforma i dati grezzi in **feature relative** tra coppie di piloti.

**PerchÃ© feature relative?**
- Un sorpasso dipende dalla **differenza** tra due piloti, non dai valori assoluti
- Es: non importa se il pilota fa 1:24, importa se Ã¨ 0.5s piÃ¹ veloce di chi ha davanti

**Feature create:**
| Feature | Significato | PerchÃ© Ã¨ importante |
|---------|-------------|---------------------|
| `Delta_LapTime` | Differenza tempo sul giro | Negativo = attaccante piÃ¹ veloce |
| `Delta_TyreLife` | Differenza usura gomme | Gomme fresche = piÃ¹ grip |
| `Compound_Advantage` | SOFT=3, MEDIUM=2, HARD=1 | Mescola piÃ¹ morbida = piÃ¹ veloce |
| `Estimated_Gap` | Gap stimato | Influenza la probabilitÃ  di DRS |

**PerchÃ© il filtro outlier (2Ïƒ)?**
- Rimuove giri anomali: pit stop, safety car, bandiere gialle
- Questi eventi non rappresentano la normale dinamica di sorpasso

---

### `pipeline/feature_processor.py`
**Cosa fa:** Prepara i dati per il training.

**Scaling con StandardScaler - PerchÃ©?**
- Le feature hanno scale diverse (posizione: 1-20, tempo: 80-100s)
- StandardScaler normalizza a media=0, std=1
- Migliora convergenza dei modelli e performance di XGBoost

**SMOTE - PerchÃ©?**
- I sorpassi sono eventi rari (~8% dei campioni)
- Modelli tendono a predire sempre "no sorpasso" senza bilanciamento
- SMOTE crea campioni sintetici della classe minoritaria

**k_neighbors adattivo - PerchÃ©?**
- SMOTE standard usa k=5, ma fallisce se ci sono meno di 5 campioni positivi
- Adattiamo automaticamente k al numero di campioni disponibili

---

### `training/model_trainer.py`
**Cosa fa:** Addestra e confronta 3 modelli, seleziona il migliore.

**PerchÃ© questi 3 modelli?**

| Modello | Pro | Contro |
|---------|-----|--------|
| **Logistic Regression** | Interpretabile, veloce, robusto | Assume linearitÃ  |
| **Random Forest** | Cattura non-linearitÃ , feature importance | PuÃ² overfittare |
| **XGBoost** | State-of-the-art, molto accurato | Black box, piÃ¹ lento |

**PerchÃ© Accuracy come metrica principale?**
- Con il bilanciamento delle classi tramite SMOTE e class_weight, l'accuracy diventa una metrica significativa
- XGBoost raggiunge la migliore accuracy (81.4%) grazie al gradient boosting

**PerchÃ© `class_weight='balanced'`?**
- Penalizza maggiormente gli errori sulla classe minoritaria
- Alternativa a SMOTE, li usiamo insieme per massimizzare l'effetto

---

### `app/app.py`
**Cosa fa:** Web application che simula il muretto box.

**PerchÃ© Streamlit?**
- Framework Python per creare webapp senza JavaScript
- Perfetto per demo di progetti ML
- Interfaccia reattiva con poche righe di codice

**ModalitÃ  ATTACK vs DEFENSE:**
- ATTACK: probabilitÃ  che il TUO pilota sorpassi
- DEFENSE: probabilitÃ  che il tuo pilota VENGA sorpassato
- Stessa logica, ma attaccante/difensore invertiti

---

### `analysis/correlation_analysis.py`
**Cosa fa:** Analizza le correlazioni tra feature.

**PerchÃ© questa analisi?**
- Identificare feature ridondanti (alta correlazione tra loro)
- Verificare correlazione con il target (IsOvertake)
- Giustificare la scelta delle feature

---

## ðŸ”¬ Scelte Tecniche Chiave

### 1. PerchÃ© XGBoost vince?

XGBoost ha la migliore accuracy (81.4%) e precision (0.44) tra i tre modelli:
- **Accuracy superiore (81.4% vs 71.2% LR)**: migliore capacitÃ  predittiva complessiva
- **Precision piÃ¹ alta (0.44 vs 0.32 LR)**: meno falsi positivi, predizioni piÃ¹ affidabili
- **Gradient Boosting**: cattura relazioni non lineari tra le feature

**Nel contesto F1:** Le predizioni di XGBoost sono piÃ¹ affidabili, riducendo i falsi allarmi al muretto box e fornendo suggerimenti piÃ¹ precisi.

### 2. PerchÃ© solo 6 feature?

- **Parsimonia**: meno feature = modello piÃ¹ generalizzabile
- **InterpretabilitÃ **: ogni feature ha un significato chiaro
- **Evitare multicollinearitÃ **: non includere sia Delta_LapTime che Attacker_LapTime + Defender_LapTime

### 3. PerchÃ© train/test 80/20?

- Standard nel ML
- Stratified split mantiene la proporzione delle classi
- Con ~1500 campioni, 20% = ~300 test samples, statisticamente significativo

---

## ðŸ“Š Interpretazione dei Risultati

### Confusion Matrix del modello finale (XGBoost):

```
                    Pred: No    Pred: SÃ¬
Actual: No           360 (TN)    38 (FP)
Actual: SÃ¬           51 (FN)     30 (TP)
```

**Lettura:**
- **30 True Positives**: sorpassi correttamente previsti âœ…
- **51 False Negatives**: sorpassi mancati âŒ
- **38 False Positives**: pochi falsi allarmi âš ï¸ (alta precision)
- **360 True Negatives**: correttamente previsto "no sorpasso" âœ…

---

## ðŸš€ Flusso di Esecuzione

```
1. data_loader.py
   â””â”€â†’ Scarica dati FastF1 â†’ f1_ground_effect_dataset.csv

2. relative_feature_builder.py
   â””â”€â†’ Crea coppie pilota-avversario â†’ f1_monza_relative_features.csv

3. feature_processor.py
   â””â”€â†’ Scale + SMOTE â†’ X_train.npy, X_test.npy, scaler.pkl

4. model_trainer.py
   â””â”€â†’ Train 3 modelli â†’ best_model.pkl, training_report.json

5. app.py
   â””â”€â†’ Carica modello â†’ Interfaccia utente interattiva
```

---

## ðŸ’¡ Possibili Domande in Sede d'Esame

### ðŸ“Œ Domande sul Dataset e Preprocessing

**Q: PerchÃ© avete scelto solo il circuito di Monza?**
> Per garantire **omogeneitÃ  dei dati**. Ogni circuito ha caratteristiche diverse (rettilinei, curve, possibilitÃ  di sorpasso). Mischiare circuiti introdurrebbe rumore e variabilitÃ  non legata alle feature del modello.

**Q: PerchÃ© usate solo 3 anni di dati?**
> PerchÃ© dal 2022 Ã¨ iniziata l'era "Ground Effect" con nuove regole aerodinamiche. Usare dati precedenti includerebbe macchine con comportamenti diversi, rendendo il modello meno accurato.

**Q: Come gestite i valori mancanti?**
> Usiamo `fillna(0)` per i missing values. Questo Ã¨ appropriato perchÃ© i missing tendono a essere giri incompleti (interruzioni) dove le feature non sono significative.

**Q: PerchÃ© rimuovete i giri oltre 2 deviazioni standard?**
> Per eliminare **outlier** come pit stop, safety car, partenze da fermo. Questi giri hanno tempi anomali che non rappresentano la normale dinamica di sorpasso.

**Q: PerchÃ© usate StandardScaler e non MinMaxScaler?**
> StandardScaler Ã¨ preferibile per i nostri modelli (incluso **XGBoost**) perchÃ© normalizza assumendo distribuzione normale. MinMaxScaler Ã¨ sensibile agli outlier e forza i valori in [0,1], perdendo informazione sulla distribuzione.

---

### ðŸ“Œ Domande sul Feature Engineering

**Q: PerchÃ© usate feature relative invece di assolute?**
> Un sorpasso dipende dalla **differenza** tra due piloti. Non importa se un pilota fa 1:24, importa quanto Ã¨ piÃ¹ veloce di chi ha davanti. Le feature relative catturano questa dinamica.

**Q: Cosa rappresenta Compound_Advantage?**
> Ãˆ la differenza tra il valore numerico delle mescole (SOFT=3, MEDIUM=2, HARD=1). Un valore positivo indica che l'attaccante ha gomme piÃ¹ performanti.

**Q: PerchÃ© non avete usato altre feature come velocitÃ  massima o settori?**
> Per **parsimonia**. PiÃ¹ feature non significa modello migliore. Le 6 feature selezionate catturano le informazioni chiave senza rischio di overfitting e multicollinearitÃ .

**Q: Come definite se un sorpasso Ã¨ avvenuto?**
> Confrontiamo la posizione del pilota nel giro N+1 con quella nel giro N. Se l'attaccante ha guadagnato posizione, `IsOvertake = 1`.

---

### ðŸ“Œ Domande sullo Sbilanciamento delle Classi

**Q: Quanto Ã¨ sbilanciato il dataset?**
> Circa **8% sorpassi vs 92% non-sorpassi**. Ãˆ fortemente sbilanciato perchÃ© i sorpassi sono eventi rari in F1.

**Q: PerchÃ© usate SMOTE?**
> SMOTE (Synthetic Minority Oversampling) genera campioni sintetici della classe minoritaria interpolando tra campioni esistenti. Questo bilancia il dataset senza perdere informazioni.

**Q: PerchÃ© usate anche class_weight='balanced'?**
> Ãˆ una tecnica complementare a SMOTE. Penalizza maggiormente gli errori sulla classe minoritaria durante il training. Le usiamo entrambe per massimizzare l'effetto.

**Q: Cosa succede se non bilanciate le classi?**
> Il modello impara a predire sempre "no sorpasso" perchÃ© questa classe domina. Ottiene 92% accuracy ma 0% recall sui sorpassi, rendendolo inutile.

**Q: PerchÃ© k_neighbors in SMOTE Ã¨ adattivo?**
> SMOTE standard usa k=5 vicini, ma fallisce se esistono meno di 5 campioni della classe minoritaria. Noi adattiamo k automaticamente a `min(5, n_minority - 1)`.

---

### ðŸ“Œ Domande sui Modelli

**Q: PerchÃ© avete scelto questi 3 modelli specifici?**
> - **Logistic Regression**: baseline interpretabile, funziona bene con feature lineari
> - **Random Forest**: cattura non-linearitÃ , fornisce feature importance
> - **XGBoost**: state-of-the-art, spesso il migliore in competizioni Kaggle

**Q: PerchÃ© XGBoost vince rispetto agli altri modelli?**
> PerchÃ© ha la **migliore Accuracy (81.4%)** e la **Precision piÃ¹ alta (0.44)**. Nel contesto F1, predizioni affidabili riducono i falsi allarmi al muretto box, fornendo suggerimenti piÃ¹ precisi per le strategie di gara.

**Q: PerchÃ© non usate reti neurali o deep learning?**
> Il dataset Ã¨ troppo piccolo (~1500 campioni). Le reti neurali richiedono migliaia/milioni di esempi e tendono a overfittare su dataset piccoli. I modelli tradizionali sono piÃ¹ appropriati.

**Q: Avete provato a fare hyperparameter tuning?**
> Usiamo configurazioni standard ottimizzate. Per un dataset di questa dimensione, il tuning aggressivo rischia overfitting. `class_weight='balanced'` e `n_estimators=100` sono scelte robuste.

**Q: Cosa significa eval_metric='logloss' in XGBoost?**
> Ãˆ la funzione di loss utilizzata per valutare il modello durante il training. Log loss (cross-entropy) Ã¨ standard per problemi di classificazione binaria.

---

### ðŸ“Œ Domande sulle Metriche

**Q: PerchÃ© non usate solo l'Accuracy?**
> Con dataset sbilanciato, l'accuracy Ã¨ **fuorviante**. Un modello che predice sempre "no sorpasso" ottiene 92% accuracy ma Ã¨ completamente inutile (0% recall).

**Q: Cosa rappresenta il F1-Score?**
> Ãˆ la **media armonica** di Precision e Recall: `F1 = 2 * (P * R) / (P + R)`. Bilancia la capacitÃ  di trovare i positivi (recall) con l'affidabilitÃ  delle predizioni positive (precision).

**Q: Come si legge la ROC-AUC?**
> Misura la capacitÃ  del modello di distinguere tra classi. AUC=0.5 = random classifier, AUC=1.0 = classificatore perfetto. Il nostro 0.75 indica buona capacitÃ  discriminativa.

**Q: PerchÃ© il Recall Ã¨ piÃ¹ importante della Precision qui?**
> Nel contesto pit wall, vogliamo **identificare tutte le opportunitÃ  di sorpasso**. Qualche falso allarme Ã¨ accettabile, ma perdere un sorpasso reale puÃ² costare posizioni in gara.

---

### ðŸ“Œ Domande sulla Webapp

**Q: Cosa fa la modalitÃ  ATTACK vs DEFENSE?**
> - **ATTACK**: calcola P(il TUO pilota sorpassi l'avversario)
> - **DEFENSE**: calcola P(il tuo pilota VENGA sorpassato)
> Internamente, invertiamo chi Ã¨ attaccante e chi difensore.

**Q: Come funziona il modello in tempo reale?**
> La webapp Ã¨ una **simulazione**. L'utente inserisce manualmente i dati. In un contesto reale, i dati verrebbero aggiornati automaticamente giro per giro tramite API F1.

**Q: PerchÃ© avete scelto Streamlit?**
> Ãˆ un framework Python per creare webapp senza JavaScript. Ideale per demo di progetti ML: interfaccia reattiva con poche righe di codice.

---

### ðŸ“Œ Domande Generali/Teoriche

**Q: Questo modello funzionerebbe su altri circuiti?**
> Le feature relative sono generalizzabili, ma le probabilitÃ  assolute potrebbero variare. Circuiti con meno sorpassi (Monaco) darebbero probabilitÃ  diverse. Servirebbe fine-tuning o retraining.

**Q: Come migliorereste il modello?**
> - Aggiungere dati da piÃ¹ circuiti con caratteristiche simili a Monza
> - Includere feature aggiuntive (meteo, DRS, posizione in curva)
> - Usare time-series models per catturare la dinamica temporale

**Q: Qual Ã¨ il limite principale del progetto?**
> Il **dataset limitato** (solo 3 GP, ~1500 campioni). Con piÃ¹ dati potremmo usare modelli piÃ¹ complessi e ottenere predizioni piÃ¹ accurate.

**Q: Come valutereste il modello in produzione?**
> Con **A/B testing**: confrontare le decisioni suggerite dal modello con quelle degli ingegneri reali su gare future, misurando se i sorpassi previsti si verificano.

---

## ðŸ“ Riassunto in 30 Secondi

> "Abbiamo creato un sistema ML che predice i sorpassi in F1 usando dati reali di Monza. Costruiamo feature relative tra piloti (delta tempo, gomme), bilanciamo il dataset sbilanciato con SMOTE, confrontiamo 3 modelli e selezioniamo XGBoost per la miglior Accuracy. La webapp permette di simulare scenari di sorpasso come un vero muretto box."
